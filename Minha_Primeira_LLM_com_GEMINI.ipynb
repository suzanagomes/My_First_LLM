{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOz9lt/XJB7AmQttBf7e0M6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suzanagomes/My_First_LLM/blob/main/Minha_Primeira_LLM_com_GEMINI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ev0vjlfBclLN"
      },
      "outputs": [],
      "source": [
        "#Instalando o SDK do Google\n",
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Configurações iniciais\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY=\"\"\n",
        "genai.configure(api_key='AIzaSyAMOcFMvRXjetO_hed0CpA3AmoWCh2nGrk') #('SECRET_KEY')"
      ],
      "metadata": {
        "id": "aXqGEjS_dv0n"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Listando os modelos disponíveis\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "HVJ3qtaVdyal",
        "outputId": "b25503a8-516f-4788-9ca5-6c3f67971342"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#configurando Parametro\n",
        "generation_config = {\n",
        "  \"candidate_count\": 1, #quantidade de respostas\n",
        "  \"temperature\": 0.5, #Esse parâmetro influencia a aleatoriedade do texto gerado: mais criativo ou menos\n",
        "}\n",
        "\n",
        "#top_p (float): Esse parâmetro controla o processo de amostragem, focando em um conjunto limitado das palavras mais prováveis ​​em cada etapa\n",
        "#top_k(int): Esse parâmetro limita diretamente o número de palavras candidatas consideradas em cada etapa de geração.\n",
        "#max_output_tokens (int): Número máximo de tokens"
      ],
      "metadata": {
        "id": "qphHk-r8dydc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorias:<br>\n",
        "* HATE (ódio): Refere-se a discurso de ódio ou conteúdo que ataca uma pessoa ou\n",
        "grupo com base em atributos como raça, religião, origem étnica, nacionalidade, sexo, deficiência, orientação sexual ou identidade de gênero.<br>\n",
        "* HARASSMENT (assédio): Refere-se a comportamento indesejado e agressivo com a intenção de irritar, alarmar ou intimidar alguém.<br>\n",
        "* SEXUAL (sexual): Provavelmente se refere a conteúdo sexualmente sugestivo.<br>\n",
        "* DANGEROUS (perigoso): Refere-se a conteúdo que pode causar danos, como\n",
        "instruções para fabricar bombas ou violência<br><br>\n",
        "\n",
        "Limite (threshold) Define o nível de gravidade necessário para que o LLM bloqueie o conteúdo daquela categoria. As opções possíveis podem incluir:\n",
        "* BLOQUEAR_NENHUM(BLOCK_NONE): Sem bloqueio (igual à opção 1).<br>\n",
        "* BLOQUEAR_BAIXO(BLOCK_LOW): Bloquear apenas o conteúdo mais extremo ou prejudicial.<br>\n",
        "* BLOQUEAR_MEDIO_E_ACIMA(BLOCK_MEDIUM_AND_ABOVE): Bloquear conteúdo de gravidade média ou superior (provavelmente a configuração usada aqui).<br>\n",
        "* BLOQUEAR_TUDO(BLOCK_ALL): Bloquear todo o conteúdo relacionado àquela categoria.<br>"
      ],
      "metadata": {
        "id": "wszL-X-Xhdvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Configuraçóes de segurança\n",
        "safety_settings={\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'SEXUAL' : 'BLOCK_NONE',\n",
        "    'DANGEROUS' : 'BLOCK_NONE'\n",
        "    }"
      ],
      "metadata": {
        "id": "6gw_duH-dygS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inicializando o modelo.\n",
        "model = genai.GenerativeModel(model_name='gemini-1.0-pro',\n",
        "                                  generation_config=generation_config,\n",
        "                                  safety_settings=safety_settings,)"
      ],
      "metadata": {
        "id": "2YCZxjjUd9jT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Definindo a consulta, começando com um histórico de conversa vazio\n",
        "response = model.generate_content(\"Qual empresa criou o chatGPT\")\n",
        "response.text\n"
      ],
      "metadata": {
        "id": "M93iSqG2d9mF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7c3af286-b103-4197-984c-bcb03246f1d6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'OpenAI'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#criando a entrada para perguntas\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "prompt = input('Esperando prompt: ')\n",
        "\n",
        "while prompt != \"fim\":\n",
        "  response = chat.send_message(prompt)\n",
        "  print(\"Resposta:\", response.text, '\\n\\n')\n",
        "  prompt = input('Esperando prompt: ')"
      ],
      "metadata": {
        "id": "pTcDhXHLi7FI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "848af636-f19a-4070-9beb-5d7ad3bcfce2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando prompt: O que e LLM\n",
            "Resposta: **LLM** significa **Large Language Model** (Modelo de Linguagem Grande).\n",
            "\n",
            "LLMs são um tipo de rede neural artificial treinada em conjuntos de dados massivos de texto. Eles são projetados para entender e gerar linguagem humana de forma semelhante à humana.\n",
            "\n",
            "**Características dos LLMs:**\n",
            "\n",
            "* **Tamanho:** LLMs são treinados em bilhões ou trilhões de parâmetros, muito maiores do que os modelos de linguagem tradicionais.\n",
            "* **Contexto:** LLMs podem levar em consideração o contexto mais amplo do texto, permitindo-lhes entender e responder a perguntas complexas.\n",
            "* **Geração:** LLMs podem gerar texto semelhante ao humano, incluindo artigos, histórias, código de computador e até mesmo poesia.\n",
            "* **Tradução:** LLMs podem traduzir idiomas com alta precisão.\n",
            "* **Resumo:** LLMs podem resumir longos trechos de texto, extraindo os pontos principais.\n",
            "* **Chatbots:** LLMs podem ser usados como chatbots para responder a perguntas, fornecer informações e se envolver em conversas.\n",
            "\n",
            "**Aplicações dos LLMs:**\n",
            "\n",
            "* Processamento de linguagem natural (PNL)\n",
            "* Geração de conteúdo\n",
            "* Tradução de idiomas\n",
            "* Resumo de texto\n",
            "* Chatbots\n",
            "* Pesquisa\n",
            "* Educação\n",
            "\n",
            "**Exemplos de LLMs:**\n",
            "\n",
            "* GPT-3 (OpenAI)\n",
            "* BERT (Google)\n",
            "* T5 (Google)\n",
            "* XLNet (Google) \n",
            "\n",
            "\n",
            "Esperando prompt: Qual a primeira coisa a se aprender sobre Processamento de linguagem natural\n",
            "Resposta: A primeira coisa a aprender sobre Processamento de Linguagem Natural (PNL) é o conceito de **tokenização**.\n",
            "\n",
            "**Tokenização** é o processo de dividir um texto em unidades menores chamadas tokens. Esses tokens podem ser palavras, caracteres, frases ou qualquer outra unidade significativa.\n",
            "\n",
            "A tokenização é importante porque é a base para muitas tarefas de PNL, como:\n",
            "\n",
            "* **Remoção de stop words:** Remover palavras comuns e irrelevantes, como \"o\", \"a\", \"de\", que não adicionam muito significado ao texto.\n",
            "* **Stemming:** Reduzir palavras à sua forma raiz, como \"correndo\", \"correu\" e \"correr\" para \"corr\".\n",
            "* **Lematização:** Reduzir palavras à sua forma canônica ou dicionária, levando em consideração o contexto, como \"correndo\" e \"correu\" para \"correr\".\n",
            "* **Marcação de parte do discurso:** Identificar a parte do discurso de cada token, como substantivo, verbo, adjetivo etc.\n",
            "* **Análise sintática:** Analisar a estrutura gramatical de uma frase, identificando sujeitos, objetos, verbos etc.\n",
            "\n",
            "Além da tokenização, outros conceitos fundamentais de PNL que você deve aprender incluem:\n",
            "\n",
            "* **Representação de texto:** Como representar texto usando vetores ou matrizes.\n",
            "* **Modelagem de linguagem:** Como prever a próxima palavra ou frase em uma sequência de texto.\n",
            "* **Aprendizado profundo:** Técnicas avançadas de aprendizado de máquina usadas em PNL.\n",
            "* **Avaliação:** Como medir o desempenho dos modelos de PNL.\n",
            "\n",
            "Compreender esses conceitos básicos fornecerá uma base sólida para explorar tópicos mais avançados de PNL. \n",
            "\n",
            "\n",
            "Esperando prompt: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat"
      ],
      "metadata": {
        "id": "vOZ9Z63wkd94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ac33c7-12d3-4fbc-d127-0e421a193df0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatSession(\n",
              "    model=genai.GenerativeModel(\n",
              "        model_name='models/gemini-1.0-pro',\n",
              "        generation_config={'candidate_count': 1, 'temperature': 0.5},\n",
              "        safety_settings={<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 8>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_HARASSMENT: 7>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 9>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 10>: <HarmBlockThreshold.BLOCK_NONE: 4>},\n",
              "        tools=None,\n",
              "        system_instruction=None,\n",
              "    ),\n",
              "    history=[glm.Content({'parts': [{'text': 'O que e LLM'}], 'role': 'user'}), glm.Content({'parts': [{'text': '**LLM** sign...LNet (Google)'}], 'role': 'model'}), glm.Content({'parts': [{'text': 'Qual a prime...uagem natural'}], 'role': 'user'}), glm.Content({'parts': [{'text': 'A primeira c...çados de PNL.'}], 'role': 'model'})]\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.history"
      ],
      "metadata": {
        "id": "UixH50cBkfxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27802b9-be28-4da7-e6f6-aaa3706c1d47"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[parts {\n",
              "   text: \"O que e LLM\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"**LLM** significa **Large Language Model** (Modelo de Linguagem Grande).\\n\\nLLMs s\\303\\243o um tipo de rede neural artificial treinada em conjuntos de dados massivos de texto. Eles s\\303\\243o projetados para entender e gerar linguagem humana de forma semelhante \\303\\240 humana.\\n\\n**Caracter\\303\\255sticas dos LLMs:**\\n\\n* **Tamanho:** LLMs s\\303\\243o treinados em bilh\\303\\265es ou trilh\\303\\265es de par\\303\\242metros, muito maiores do que os modelos de linguagem tradicionais.\\n* **Contexto:** LLMs podem levar em considera\\303\\247\\303\\243o o contexto mais amplo do texto, permitindo-lhes entender e responder a perguntas complexas.\\n* **Gera\\303\\247\\303\\243o:** LLMs podem gerar texto semelhante ao humano, incluindo artigos, hist\\303\\263rias, c\\303\\263digo de computador e at\\303\\251 mesmo poesia.\\n* **Tradu\\303\\247\\303\\243o:** LLMs podem traduzir idiomas com alta precis\\303\\243o.\\n* **Resumo:** LLMs podem resumir longos trechos de texto, extraindo os pontos principais.\\n* **Chatbots:** LLMs podem ser usados como chatbots para responder a perguntas, fornecer informa\\303\\247\\303\\265es e se envolver em conversas.\\n\\n**Aplica\\303\\247\\303\\265es dos LLMs:**\\n\\n* Processamento de linguagem natural (PNL)\\n* Gera\\303\\247\\303\\243o de conte\\303\\272do\\n* Tradu\\303\\247\\303\\243o de idiomas\\n* Resumo de texto\\n* Chatbots\\n* Pesquisa\\n* Educa\\303\\247\\303\\243o\\n\\n**Exemplos de LLMs:**\\n\\n* GPT-3 (OpenAI)\\n* BERT (Google)\\n* T5 (Google)\\n* XLNet (Google)\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"Qual a primeira coisa a se aprender sobre Processamento de linguagem natural\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"A primeira coisa a aprender sobre Processamento de Linguagem Natural (PNL) \\303\\251 o conceito de **tokeniza\\303\\247\\303\\243o**.\\n\\n**Tokeniza\\303\\247\\303\\243o** \\303\\251 o processo de dividir um texto em unidades menores chamadas tokens. Esses tokens podem ser palavras, caracteres, frases ou qualquer outra unidade significativa.\\n\\nA tokeniza\\303\\247\\303\\243o \\303\\251 importante porque \\303\\251 a base para muitas tarefas de PNL, como:\\n\\n* **Remo\\303\\247\\303\\243o de stop words:** Remover palavras comuns e irrelevantes, como \\\"o\\\", \\\"a\\\", \\\"de\\\", que n\\303\\243o adicionam muito significado ao texto.\\n* **Stemming:** Reduzir palavras \\303\\240 sua forma raiz, como \\\"correndo\\\", \\\"correu\\\" e \\\"correr\\\" para \\\"corr\\\".\\n* **Lematiza\\303\\247\\303\\243o:** Reduzir palavras \\303\\240 sua forma can\\303\\264nica ou dicion\\303\\241ria, levando em considera\\303\\247\\303\\243o o contexto, como \\\"correndo\\\" e \\\"correu\\\" para \\\"correr\\\".\\n* **Marca\\303\\247\\303\\243o de parte do discurso:** Identificar a parte do discurso de cada token, como substantivo, verbo, adjetivo etc.\\n* **An\\303\\241lise sint\\303\\241tica:** Analisar a estrutura gramatical de uma frase, identificando sujeitos, objetos, verbos etc.\\n\\nAl\\303\\251m da tokeniza\\303\\247\\303\\243o, outros conceitos fundamentais de PNL que voc\\303\\252 deve aprender incluem:\\n\\n* **Representa\\303\\247\\303\\243o de texto:** Como representar texto usando vetores ou matrizes.\\n* **Modelagem de linguagem:** Como prever a pr\\303\\263xima palavra ou frase em uma sequ\\303\\252ncia de texto.\\n* **Aprendizado profundo:** T\\303\\251cnicas avan\\303\\247adas de aprendizado de m\\303\\241quina usadas em PNL.\\n* **Avalia\\303\\247\\303\\243o:** Como medir o desempenho dos modelos de PNL.\\n\\nCompreender esses conceitos b\\303\\241sicos fornecer\\303\\241 uma base s\\303\\263lida para explorar t\\303\\263picos mais avan\\303\\247ados de PNL.\"\n",
              " }\n",
              " role: \"model\"]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Melhorando a visualização\n",
        "#Código disponível em https://ai.google.dev/tutorials/python_quickstart#import_packages\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "#Imprimindo o histórico\n",
        "for message in chat.history:\n",
        "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "  print('-------------------------------------------')"
      ],
      "metadata": {
        "id": "NsFP0Spokg3j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "d18d3edc-7d5d-4ce0-a078-8115774c519f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: O que e LLM"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: **LLM** significa **Large Language Model** (Modelo de Linguagem Grande).\n> \n> LLMs são um tipo de rede neural artificial treinada em conjuntos de dados massivos de texto. Eles são projetados para entender e gerar linguagem humana de forma semelhante à humana.\n> \n> **Características dos LLMs:**\n> \n> * **Tamanho:** LLMs são treinados em bilhões ou trilhões de parâmetros, muito maiores do que os modelos de linguagem tradicionais.\n> * **Contexto:** LLMs podem levar em consideração o contexto mais amplo do texto, permitindo-lhes entender e responder a perguntas complexas.\n> * **Geração:** LLMs podem gerar texto semelhante ao humano, incluindo artigos, histórias, código de computador e até mesmo poesia.\n> * **Tradução:** LLMs podem traduzir idiomas com alta precisão.\n> * **Resumo:** LLMs podem resumir longos trechos de texto, extraindo os pontos principais.\n> * **Chatbots:** LLMs podem ser usados como chatbots para responder a perguntas, fornecer informações e se envolver em conversas.\n> \n> **Aplicações dos LLMs:**\n> \n> * Processamento de linguagem natural (PNL)\n> * Geração de conteúdo\n> * Tradução de idiomas\n> * Resumo de texto\n> * Chatbots\n> * Pesquisa\n> * Educação\n> \n> **Exemplos de LLMs:**\n> \n> * GPT-3 (OpenAI)\n> * BERT (Google)\n> * T5 (Google)\n> * XLNet (Google)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Qual a primeira coisa a se aprender sobre Processamento de linguagem natural"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: A primeira coisa a aprender sobre Processamento de Linguagem Natural (PNL) é o conceito de **tokenização**.\n> \n> **Tokenização** é o processo de dividir um texto em unidades menores chamadas tokens. Esses tokens podem ser palavras, caracteres, frases ou qualquer outra unidade significativa.\n> \n> A tokenização é importante porque é a base para muitas tarefas de PNL, como:\n> \n> * **Remoção de stop words:** Remover palavras comuns e irrelevantes, como \"o\", \"a\", \"de\", que não adicionam muito significado ao texto.\n> * **Stemming:** Reduzir palavras à sua forma raiz, como \"correndo\", \"correu\" e \"correr\" para \"corr\".\n> * **Lematização:** Reduzir palavras à sua forma canônica ou dicionária, levando em consideração o contexto, como \"correndo\" e \"correu\" para \"correr\".\n> * **Marcação de parte do discurso:** Identificar a parte do discurso de cada token, como substantivo, verbo, adjetivo etc.\n> * **Análise sintática:** Analisar a estrutura gramatical de uma frase, identificando sujeitos, objetos, verbos etc.\n> \n> Além da tokenização, outros conceitos fundamentais de PNL que você deve aprender incluem:\n> \n> * **Representação de texto:** Como representar texto usando vetores ou matrizes.\n> * **Modelagem de linguagem:** Como prever a próxima palavra ou frase em uma sequência de texto.\n> * **Aprendizado profundo:** Técnicas avançadas de aprendizado de máquina usadas em PNL.\n> * **Avaliação:** Como medir o desempenho dos modelos de PNL.\n> \n> Compreender esses conceitos básicos fornecerá uma base sólida para explorar tópicos mais avançados de PNL."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}